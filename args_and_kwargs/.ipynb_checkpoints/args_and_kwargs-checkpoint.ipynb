{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa371167-5f06-4eb1-a98c-3fffbec90f6b",
   "metadata": {},
   "source": [
    "# *args and **kwargs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00981f19-2236-4e0c-9901-d097b92d448b",
   "metadata": {},
   "source": [
    "which are very important in Python, especially in object-oriented programming, decorators, data pipelines, and AI/ML frameworks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6358e0e-b77e-413e-bdba-513c99190c09",
   "metadata": {},
   "source": [
    "They let your functions accept a variable number of arguments, meaning you can pass as many inputs as you want, even if you don’t know how many beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ba366-4f86-4e68-8871-0819a6ae57ef",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|l|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Syntax} & \\textbf{Type} & \\textbf{Example Input} & \\textbf{Stored As} \\\\\n",
    "\\hline\n",
    "\\texttt{*args} & Positional arguments & \\texttt{func(1, 2, 3)} & Tuple \\rightarrow \\texttt{(1, 2, 3)} \\\\\n",
    "\\hline\n",
    "\\texttt{**kwargs} & Keyword arguments & \\texttt{func(a=1, b=2)} & Dict \\rightarrow \\texttt{\\{'a':1, 'b':2\\}} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017eff96-3709-4d7d-9bf1-312c7f0b62f1",
   "metadata": {},
   "source": [
    "#### Using *args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58b5f8b4-c3c9-4b68-8e0e-b8250f827174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers: (2, 5)\n",
      "7\n",
      "Numbers: (2, 5, 10, 20)\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "def add_numbers(*args):\n",
    "    total = sum(args)\n",
    "    print(\"Numbers:\", args)\n",
    "    return total\n",
    "\n",
    "print(add_numbers(2, 5))\n",
    "print(add_numbers(2, 5, 10, 20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fec5748-0a90-46b1-9be1-2d3cea2c4c5a",
   "metadata": {},
   "source": [
    "#### Using **kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1e5e8a0-e17c-470b-bbb2-3b74c69b63bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: Efe\n",
      "course: AI\n",
      "year: 2025\n"
     ]
    }
   ],
   "source": [
    "def print_student(**kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print_student(name=\"Efe\", course=\"AI\", year=2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b673d119-88f7-49b1-a721-15884ec54262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: Efe\n",
      "Extra args: ('AI', 'Sussex')\n",
      "Extra kwargs: {'age': 36, 'mode': 'part-time'}\n"
     ]
    }
   ],
   "source": [
    "def student_info(name, *args, **kwargs):\n",
    "    print(\"Name:\", name)\n",
    "    print(\"Extra args:\", args)\n",
    "    print(\"Extra kwargs:\", kwargs)\n",
    "\n",
    "student_info(\"Efe\", \"AI\", \"Sussex\", age=36, mode=\"part-time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e05b2ba-7ac6-4951-bd3b-a3a7991af43d",
   "metadata": {},
   "source": [
    "### Argument unpacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1aedb86-c7a0-47e9-972a-0eae7b93edb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3\n",
      "1 2 3\n"
     ]
    }
   ],
   "source": [
    "def show(a, b, c):\n",
    "    print(a, b, c)\n",
    "\n",
    "args = (1, 2, 3)\n",
    "kwargs = {'a': 1, 'b': 2, 'c': 3}\n",
    "\n",
    "show(*args)     # unpack tuple\n",
    "show(**kwargs)  # unpack dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adba3092-c8f9-441c-ad31-28087254162c",
   "metadata": {},
   "source": [
    "### Real-World Uses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331dafc7-d12c-450a-9660-850bcc4240d8",
   "metadata": {},
   "source": [
    "#### A. OOP — Passing args to super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93bee547-a40c-4355-842e-46ebe7457268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, name, age):\n",
    "        self.name = name\n",
    "        self.age = age\n",
    "\n",
    "class MScStudent(Student):\n",
    "    def __init__(self, *args, course=\"AI\", **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.course = course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d29f2e8-68bd-4e73-8abe-12a7c735864e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efe 36 AI\n"
     ]
    }
   ],
   "source": [
    "efe = MScStudent(\"Efe\", 36)\n",
    "print(efe.name, efe.age, efe.course)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4baa5-5e7b-4db4-8781-79e6bce6f151",
   "metadata": {},
   "source": [
    "#### B. Decorators — Flexible wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09a8986b-b080-4d6f-9dbf-27bbfedfe3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: (5,) {'y': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_args(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(\"Arguments:\", args, kwargs)\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@log_args\n",
    "def multiply(x, y):\n",
    "    return x * y\n",
    "\n",
    "multiply(5, y=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c6966-ef5c-4256-a076-4300566192a9",
   "metadata": {},
   "source": [
    "#### C. Machine Learning — Function wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201913fb-baa9-463d-8232-ab3675a9ab84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, *datasets, **params):\n",
    "    print(\"Datasets:\", datasets)\n",
    "    print(\"Hyperparameters:\", params)\n",
    "\n",
    "train_model(\"DecisionTree\", \"train.csv\", \"test.csv\", max_depth=5, criterion=\"gini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a6c25-ce43-4b38-9399-fe40dfc77846",
   "metadata": {},
   "source": [
    "- Always *args before **kwargs\n",
    "- Unpacking wrongly: Using func(*kwargs) instead of func(**kwargs)\n",
    "- args is tuple, kwargs is dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bba77b-4e37-427e-8372-d48323ed106e",
   "metadata": {},
   "source": [
    "#### Combine with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eac5d76b-6248-4f85-b838-172d8a07493d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Efe from UK\n",
      "Skills: ('Python', 'AI')\n",
      "Details: {'degree': 'MSc', 'year': 2025}\n"
     ]
    }
   ],
   "source": [
    "def describe(name, *skills, country=\"UK\", **details):\n",
    "    print(f\"{name} from {country}\")\n",
    "    print(\"Skills:\", skills)\n",
    "    print(\"Details:\", details)\n",
    "\n",
    "describe(\"Efe\", \"Python\", \"AI\", degree=\"MSc\", year=2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6b7c25-2bf8-41aa-ae7c-d26b0eec535e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{|l|l|l|l|l|}\n",
    "\\hline\n",
    "\\textbf{Symbol} & \\textbf{Meaning} & \\textbf{Data Type} & \\textbf{Example Input} & \\textbf{Example Storage}\\\\\n",
    "\\hline\n",
    "\\texttt{*args} & \\texttt{Variable Positional Args} & \\texttt{Tuple} & \\texttt{func(1, 2, 3)} & \\texttt{(1, 2, 3)} \\\\\n",
    "\\hline\n",
    "\\texttt{**kwargs} & \\texttt{Variable Keyword Args} & \\texttt{Dict (Dictionary)} & \\texttt{func(a=1, b=2)} & \\texttt{\\{'a': 1, 'b': 2\\}} \\\\\n",
    "\\hline\n",
    "\\texttt{*} & \\texttt{unpack iterable} & \\texttt{list/tuple} & \\texttt{func(*[1,2,3])} & \\texttt{func(1,2,3)} \\\\\n",
    "\\hline\n",
    "\\texttt{**} & \\texttt{unpack dict} & \\texttt{dict} & \\texttt{func(**{'a':1})} & \\texttt{func(a=1)} \\\\\n",
    "\\hline\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2a9f9-76ad-4c72-9634-a6e4532934fb",
   "metadata": {},
   "source": [
    "### Why *args and **kwargs matter in OOP (Class Inheritance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf027bb-50ed-40cb-abff-17458644abbb",
   "metadata": {},
   "source": [
    "When you inherit from a base class and add new parameters, you often don’t want to rewrite all the parent’s arguments manually, that’s where *args and **kwargs keep your code flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e300d4a5-08ec-4689-81e1-71c0702de7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# without *arg and ** kwargs\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, name, version):\n",
    "        self.name = name\n",
    "        self.version = version\n",
    "\n",
    "class NNModel(Model):\n",
    "    def __init__(self, name, version, layers):\n",
    "        # You must call the parent manually\n",
    "        Model.__init__(self, name, version)\n",
    "        self.layers = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "13aeb875-9c46-43a8-83c7-9a0610e86a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionNet 1.0 5\n"
     ]
    }
   ],
   "source": [
    "# with *arg and *kwargs\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, name, version):\n",
    "        self.name = name\n",
    "        self.version = version\n",
    "\n",
    "class NNModel(Model):\n",
    "    def __init__(self, *args, layers=3, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.layers = layers\n",
    "\n",
    "m = NNModel(\"VisionNet\", \"1.0\", layers=5)\n",
    "print(m.name, m.version, m.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6818ed72-5334-438a-b0f5-3b9e5aa041df",
   "metadata": {},
   "source": [
    "**Why it’s powerful**\n",
    "\n",
    "- Any new parameters added to Model later will automatically work, no need to change every subclass.\n",
    "- This is exactly how PyTorch’s nn.Module or sklearn BaseEstimator handle hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc3005f-dc0c-47ff-ba83-874b9281001c",
   "metadata": {},
   "source": [
    "### How AI frameworks use *args and **kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60332942-fd29-445f-b5de-ca92d202b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "# Here, super().__init__(*args, **kwargs) lets your model inherit the initialization of nn.Module.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self, *args, input_dim=10, hidden_dim=20, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.fc = nn.Linear(input_dim, hidden_dim)\n",
    "\n",
    "net = MyNet(input_dim=8, hidden_dim=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfa53a1-b30f-45a0-931b-3a75bac34b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn\n",
    "class MyClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, *args, learning_rate=0.01, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.learning_rate = learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0851dda-f697-4e43-9d09-bb71328085b4",
   "metadata": {},
   "source": [
    "### How decorators rely on *args and **kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe59ced-ef1c-4959-8f5f-9059d0113cd7",
   "metadata": {},
   "source": [
    "When you write a decorator, you don’t know in advance how many arguments the function it wraps will have, so decorators must use *args and **kwargs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0a2667c6-cbdd-42f2-b4f0-d64313b7b885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling multiply with (4,) and {'b': 5}\n",
      "multiply returned 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_func(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"Calling {func.__name__} with {args} and {kwargs}\")\n",
    "        result = func(*args, **kwargs)\n",
    "        print(f\"{func.__name__} returned {result}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@log_func\n",
    "def multiply(a, b):\n",
    "    return a * b\n",
    "\n",
    "multiply(4, b=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e89ae35c-ebac-40f7-a61e-6dd4740a5c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_model took 0.0000s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'done'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def timer(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end = time.time()\n",
    "        print(f\"{func.__name__} took {end - start:.4f}s\")\n",
    "        return result\n",
    "    return wrapper\n",
    "\n",
    "@timer\n",
    "def train_model(model, epochs=10):\n",
    "    for _ in range(epochs):\n",
    "        pass  # training loop\n",
    "    return \"done\"\n",
    "\n",
    "train_model(\"MyModel\", epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76c4410-43b1-436f-8026-818d8aecce14",
   "metadata": {},
   "source": [
    "### AI pipelines example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95034766-c5ee-4092-b24a-12c0a5b16975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stage: load_data\n",
      "Loading from dataset.csv\n",
      "Stage: train\n",
      "Training DecisionTree with lr=0.05, epochs=10\n",
      "Stage: evaluate\n",
      "Evaluating DecisionTree\n"
     ]
    }
   ],
   "source": [
    "def log_stage(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        print(f\"Stage: {func.__name__}\")\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper\n",
    "\n",
    "@log_stage\n",
    "def load_data(source, *args, **kwargs):\n",
    "    print(f\"Loading from {source}\")\n",
    "\n",
    "@log_stage\n",
    "def train(model, *args, lr=0.01, epochs=10, **kwargs):\n",
    "    print(f\"Training {model} with lr={lr}, epochs={epochs}\")\n",
    "\n",
    "@log_stage\n",
    "def evaluate(model, *args, **kwargs):\n",
    "    print(f\"Evaluating {model}\")\n",
    "\n",
    "# full pipeline\n",
    "load_data(\"dataset.csv\", size=1000)\n",
    "train(\"DecisionTree\", lr=0.05)\n",
    "evaluate(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52807b92-523e-40bd-bf02-985ae5cb7ee5",
   "metadata": {},
   "source": [
    "#### Key internal mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b30ba183-72d0-4e63-bb16-0e8579ed3007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2, 3) {'name': 'Efe'}\n",
      "(1, 2) {'a': 10, 'b': 20}\n"
     ]
    }
   ],
   "source": [
    "# Pack → *args and **kwargs collect arguments\n",
    "def f(*args, **kwargs):\n",
    "    print(args, kwargs)\n",
    "\n",
    "f(1, 2, 3, name=\"Efe\")\n",
    "\n",
    "# Unpack → spread tuple or dict into arguments\n",
    "params = {'a': 10, 'b': 20}\n",
    "f(*[1, 2], **params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1bec2f-a75f-4c3a-8ee4-b43334bd2ca6",
   "metadata": {},
   "source": [
    "#### Combine with @staticmethod or @classmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0b64fe20-8341-4cc9-acc7-d35080202d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args: (1, 2, 3)\n",
      "Kwargs: {'x': 10}\n"
     ]
    }
   ],
   "source": [
    "class Utils:\n",
    "    @staticmethod\n",
    "    def summary(*args, **kwargs):\n",
    "        print(\"Args:\", args)\n",
    "        print(\"Kwargs:\", kwargs)\n",
    "\n",
    "Utils.summary(1, 2, 3, x=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e064d68a-6a8f-4ae1-ac90-d0efe893d24f",
   "metadata": {},
   "source": [
    "# Mini Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921e9df5-8fec-4b66-aa6f-e981ecbcc885",
   "metadata": {},
   "source": [
    "##### Utilities: robust decorators that accept any signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41da4877-3256-4272-9c5a-a1ff77660f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "\n",
    "def log_and_time(stage_name=None):\n",
    "    \"\"\"Decorator that logs args/kwargs and measures runtime, for ANY function.\"\"\"\n",
    "    def deco(func):\n",
    "        @functools.wraps(func) # keep original name & signature for help(), IDEs, etc.\n",
    "        def wrapper(*args, **kwargs):\n",
    "            label = stage_name or func.__name__\n",
    "            print(f\"{label}: args={args}, kwargs={kwargs}\")\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                out = func(*args, **kwargs)  # pass through all args as-is\n",
    "            finally:\n",
    "                dt = time.time() - t0\n",
    "                print(f\"{label} took {dt:.4f}s\")\n",
    "            return out\n",
    "        return wrapper\n",
    "    return deco\n",
    "\n",
    "# Why *args, **kwargs here?\n",
    "# A decorator must accept whatever the wrapped function accepts.\n",
    "# We forward everything unchanged so the original behavior is intact."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c92f7863-cc19-41f0-b04a-a9f6eb7cb3c6",
   "metadata": {},
   "source": [
    "##### A “framework-like” OOP base with flexible init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "89e67252-6ba8-48d4-9772-237e448707d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    \"\"\"Minimal training-ready base. Accepts flexible hyperparams via **kwargs.\"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # Accept *any* extra settings without breaking subclasses.\n",
    "        self.config = dict(kwargs)  # keep a copy for reproducibility\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def parameters(self):\n",
    "        # Imagine this returns trainable params; here we just mock it.\n",
    "        return [\"W\", \"b\"]\n",
    "\n",
    "# The base class absorbs future options via **kwargs so subclasses don’t break when you add new knobs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869bfe95-2685-49ce-b3f1-2ac513e0bc1f",
   "metadata": {},
   "source": [
    "##### A subclass that extends the signature but forwards the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5735d4cb-1ac8-48fc-b745-5064972af1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(BaseModel):\n",
    "    def __init__(self, input_dim, hidden_dim=32, output_dim=2, *args, **kwargs):\n",
    "        # consume the arguments we care about\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "        # forward anything else to BaseModel (logging flags, seeds, etc.)\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        # pretend we run a forward pass; kwargs can carry flags like training=True, dropout=0.1\n",
    "        training = kwargs.get(\"training\", False)\n",
    "        return {\"logits\": f\"fake({len(x)} samples) training={training}\"}\n",
    "\n",
    "# Why both *args and **kwargs in __init__?\n",
    "# You rarely need *args for initializers, but including it makes the class “bulletproof” if a parent someday requires positional args."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d05c364-753e-4510-97cd-5be0922e34ed",
   "metadata": {},
   "source": [
    "##### Trainer functions that accept/forward flexible knobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f78b8f02-0c09-48fb-8bdb-45f2939659bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_and_time(\"fit\")\n",
    "def fit(model, data, *args, epochs=3, lr=1e-2, **kwargs):\n",
    "    \"\"\"\n",
    "    A minimal trainer:\n",
    "      - Recognizes epochs, lr\n",
    "      - Forwards the rest (like callbacks=True, training=True) to lower layers\n",
    "    \"\"\"\n",
    "    print(f\"Parameters: {model.parameters()}\")\n",
    "    history = []\n",
    "\n",
    "    # Extract/consume some advanced options, forward the rest\n",
    "    # (classic pattern: pop known keys, pass leftovers forward)\n",
    "    callback = kwargs.pop(\"callback\", None)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Simulate a forward call, forwarding remaining kwargs\n",
    "        out = model.forward(data, training=True, **kwargs)\n",
    "        loss = 0.123  # pretend\n",
    "        history.append({\"epoch\": epoch, \"loss\": loss})\n",
    "        if callback:\n",
    "            callback(epoch=epoch, loss=loss, out=out)\n",
    "    return history\n",
    "\n",
    "\n",
    "@log_and_time(\"evaluate\")\n",
    "def evaluate(model, data, **kwargs):\n",
    "    # Forward evaluation flags like metric=\"f1\", batch_size=128, etc.\n",
    "    out = model.forward(data, training=False, **kwargs)\n",
    "    metrics = {\"accuracy\": 0.87}  # pretend\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Key patterns:\n",
    "# Keyword-only hyperparams (epochs, lr) after *args makes callsites clearer.\n",
    "# kwargs.pop(...) to consume known keys and pass the rest downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e63ae5e-1f86-4960-a1ec-1c01fc6832c1",
   "metadata": {},
   "source": [
    "##### Putting it together (unpacking config dicts cleanly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "693a2602-2391-45b6-9c22-01f1daf01cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model config snapshot: {'seed': 42, 'experiment': 'run_001'}\n",
      "fit: args=(<__main__.MLP object at 0x0000018BA2F3BCE0>, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255]), kwargs={'epochs': 5, 'lr': 0.005, 'metric': 'f1', 'dropout': 0.1, 'callback': <function <lambda> at 0x0000018BAA8837E0>}\n",
      "Parameters: ['W', 'b']\n",
      "  ↳ callback: {'epoch': 1, 'loss': 0.123, 'out': {'logits': 'fake(256 samples) training=True'}}\n",
      "  ↳ callback: {'epoch': 2, 'loss': 0.123, 'out': {'logits': 'fake(256 samples) training=True'}}\n",
      "  ↳ callback: {'epoch': 3, 'loss': 0.123, 'out': {'logits': 'fake(256 samples) training=True'}}\n",
      "  ↳ callback: {'epoch': 4, 'loss': 0.123, 'out': {'logits': 'fake(256 samples) training=True'}}\n",
      "  ↳ callback: {'epoch': 5, 'loss': 0.123, 'out': {'logits': 'fake(256 samples) training=True'}}\n",
      "fit took 0.0000s\n",
      "History: [{'epoch': 1, 'loss': 0.123}, {'epoch': 2, 'loss': 0.123}, {'epoch': 3, 'loss': 0.123}, {'epoch': 4, 'loss': 0.123}, {'epoch': 5, 'loss': 0.123}]\n",
      "evaluate: args=(<__main__.MLP object at 0x0000018BA2F3BCE0>, [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127]), kwargs={'metric': 'accuracy', 'batch_size': 256}\n",
      "evaluate took 0.0000s\n",
      "Metrics: {'accuracy': 0.87}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Configs you might load from YAML/JSON/argparse\n",
    "    model_cfg = {\n",
    "        \"input_dim\": 100,\n",
    "        \"hidden_dim\": 64,\n",
    "        \"output_dim\": 3,\n",
    "        \"seed\": 42,              # not used by MLP directly, but BaseModel stores it\n",
    "        \"experiment\": \"run_001\", # also stored in BaseModel.config\n",
    "    }\n",
    "\n",
    "    train_cfg = {\n",
    "        \"epochs\": 5,\n",
    "        \"lr\": 5e-3,\n",
    "        \"metric\": \"f1\",          # unused by fit(), but forwarded to forward/evaluate\n",
    "        \"dropout\": 0.1,          # forwarded\n",
    "        \"callback\": lambda **info: print(\"  ↳ callback:\", info),\n",
    "    }\n",
    "\n",
    "    eval_cfg = {\n",
    "        \"metric\": \"accuracy\",\n",
    "        \"batch_size\": 256,       # forwarded\n",
    "    }\n",
    "\n",
    "    # Build model with **unpacking**\n",
    "    model = MLP(**model_cfg)\n",
    "    print(\"Model config snapshot:\", model.config)\n",
    "\n",
    "    # Fake “data”\n",
    "    X_train = list(range(256))\n",
    "    X_test  = list(range(128))\n",
    "\n",
    "    # Train & evaluate — configs unpacked\n",
    "    hist = fit(model, X_train, **train_cfg)\n",
    "    print(\"History:\", hist)\n",
    "\n",
    "    metrics = evaluate(model, X_test, **eval_cfg)\n",
    "    print(\"Metrics:\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4671073-2283-4264-84e5-d5f70ff9c271",
   "metadata": {},
   "source": [
    "**What you’ll see:**\n",
    "\n",
    "- The decorators printing calls + timings.\n",
    "\n",
    "- fit() and evaluate() accepting flexible options.\n",
    "\n",
    "- MLP absorbing extras cleanly via super().__init__(**kwargs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ccdf14-6ff5-43bb-886b-a335e8f1c8f7",
   "metadata": {},
   "source": [
    "## Some Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "82302bb3-282e-47f9-866e-7cc19dabf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decorator that doesn’t break signatures\n",
    "\n",
    "def safe_decorator(func):\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        return func(*args, **kwargs)\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f85fb967-9711-4f23-bbda-abc255f7d918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consume-and-forward\n",
    "\n",
    "def stage(*args, **kwargs):\n",
    "    important = kwargs.pop(\"important\", None)\n",
    "    return next_stage(*args, **kwargs)  # forwards the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "da5bb16a-4acb-4d06-86ad-70eda14514ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force keyword-only for clarity\n",
    "\n",
    "def train(model, *, epochs=10, lr=1e-3, **kwargs):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26268f1-ff24-4164-8163-b2f33741a4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dict merge/unpack\n",
    "\n",
    "base = {\"lr\": 1e-3}\n",
    "override = {\"lr\": 5e-4, \"epochs\": 20}\n",
    "cfg = {**base, **override}  # override wins\n",
    "func(**cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2bce7e-8864-4127-898d-7677016481a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
